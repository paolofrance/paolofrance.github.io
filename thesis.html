<!DOCTYPE html>
<html lang="en">
<head>   
    <script src="jquery/jquery-3.6.0.min.js"></script> 
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="script/load.js"></script>
    <script src="script/thesis.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>

<body>


<div id="header"></div>
<link rel="stylesheet" href="style/thesis.css"> 
<div id="my_navbar"></div>




<div class="main">



  <h2>Current open thesis</h2>

  <section>
    <nav>
      <ul>
        <li data-rel="1" >Learning role arbitration between Human and Robot</li>
        <li data-rel="2" >Inverse Optimal Control/Inverse Reinforcement Learning for physical Human-Robot Interaction</li>
        <li data-rel="3" >Inverse Optimal Control/Inverse Reinforcement Learning for Human-Human dyad</li>
        <li data-rel="4" >Bayesian optimization for complex robot workspaces optimization</li>
        <li data-rel="5" >Nonlinear Cooperative Differential Game Theory for physical Human-Robot Interaction</li>
      </ul>
    </nav>
    
    <section >
      <article>

        <h4>Learning role arbitration between Human and Robot</h4>
        <p>
          Role Arbitration defines the mechanism that assigns control of a shared task to either the human or the robot. In a shared task between a human and a robot, it is important to select who has the control authority.
          The objective of this thesis is to define a law that allows smooth and continuous role arbitration between a human and a robot.
          Possible features to be considered can be minimum jerk, safety requirements, foreseen collisions.

          The main activities will be: 
          <ol> 
            <li> 
              identification and optimization of the role arbitration law (possible techniques are Fuzzy logic, reinforcement learning)
            </li>
            <li>
              Design of experiments and implementation of the control law on a real robot
            </li>
            <li>
              Data collection and analysis to compare the proposed approach with other states of the art
              approaches
            </li>
        </ol>
        <ul>
          Note: preferred skills (can also be acquired during the thesis):
          <li> Python/C++</li>
          <li> Matlab</li>
          <li> ROS</li>
        </ul>
          
        </p>

      </article>
    </section>

    <section class="thesis" >
      <article>
        <h4>IOC/IRL for physical Human-Robot Interaction </h4>
        <p>
          Optimal control aims at minimizing a cost function to provide optimal control input. Conversely, Inverse Optimal Control seeks the cost function that produced a known control input, given such control input and state history.
          The objective of the thesis is to recover the cost function of a human performing a shared task with a robot, and analysis of the data to understand and analyze if the human prefers a Cooperative or Non-Cooperative behavior of the robot.
          This will allow future applications to design controllers for more natural Human-Robot Interaction.
          <br>
          The main activities will be: 
          <ol> 
            <li> 
              identification of the cost function’s relevant features (i.e., cost function’s structure)
            </li>
            <li>
              implementation of IOC/IRL algorithms and selection of the best one
            </li>
            <li>
              design of experiments and data collection with a robot.
            </li>
            <li>
              analysis of the data to understand which model fits better (cooperative/non-cooperative/others)
            </li>
        </ol>
        <ul>
          Note: preferred skills (can also be acquired during the thesis):
          <li> Python</li>
          <li> Matlab</li>
          <li> ROS</li>
        </ul>
        </p>
      </article>
    </section>

    <section class="thesis" >
      <article>
        <h4>IOC/IRL to understand human behavior</h4>
        <p>
          Optimal control aims at minimizing a cost function to provide optimal control input. Conversely, Inverse Optimal Control seeks the cost function that produced a known control input, given such control input and state history.
          The objective of the thesis is to recover the cost function of a humans' dyad performing a shared task, and analysis of the data to understand if their behavior can be described by Cooperative or Non-Cooperative game theory or other models (to be identified), and which better fits.
          This will allow future applications to design controllers for more natural Human-Robot Interaction.
          <br>
          The main activities will be: 
          <ol> 
            <li> 
              identification of the cost function’s relevant features (i.e., cost function’s structure)
            </li>
            <li>
              implementation of IOC/IRL algorithms and selection of the best one
            </li>
            <li>
              design of experiments and data collection with human dyads.
            </li>
            <li>
              analysis of the data to understand which model fits better (cooperative/non-cooperative/others)
            </li>
        </ol>
        <ul>
          Note: preferred skills (can also be acquired during the thesis):
          <li> Python</li>
          <li> Matlab</li>
          <li> ROS</li>
        </ul>
      </p>
      </article>
    </section>

    <section class="thesis" >
      <article>
        <h4>Bayesian optimization for robotic workcell optimization</h4>
        <p>
          The robotic workcell design can be a long and complex work even for experts, particularly when complex/cluttered environments are considered. Possible scenarios can be mobile robot placement in cluttered environments, multirobot placement around a workstation, etc.
          The objective of the thesis will be the design of a tool for fast workcell design, based on the maximization of some specified index
          The main activities will be:
          <ol> 
            <li> 
              Optimization problem formulation and definition of one (or more) performance index
            </li>
            <li>
              implementation/use of Bayesian optimization algorithm to solve the problem
            </li>
            <li>
              analysis of the results and comparison with other state of the art algorithm
            </li>
        </ol>
        <ul>
          Note: preferred skills (can also be acquired during the thesis):
          <li> Python</li>
          <li> ROS</li>
          <li> C++</li>
        </ul>
        </p>

      </article>
    </section>

    <section class="thesis" >
      <article>
        <h4>Nonlinear Cooperative Differential Game Theory for physical Human-Robot Interaction</h4>
        <p>
          Game theory is the study of mathematical models of strategic interactions among rational agents.
          It was proven that also in physical Human-Robot Interaction, game theory provides a useful tool for modeling and control of the robot.
          Many studies investigates the Linear case, this thesis wants to investigate the nonlinear case, implements possible solutions and verify the method on a real robotic platform.
        </p>
      </article>
    </section>
  </section>

  <h2>Previous work</h2>





    
    
   
    
<div class="old-thesis-list">
  <ul>  
    <p class="on-clic" data-rel="1">"Recurrent Neural Network for online human intention prediction in physical Human-Robot cooperation", Fabio Bertini, PoliMi, 2022</p>
    <!-- <li class="old-thesis">
      <p>
        The thesis work focussed on the definition of a model based on Recurrent Neural Network (RNN) to identify the intention of a human operator working in physical contact with a robot in a physical Human-Robot Interaction (pHRI) framework.
        The interaction and the robot control are modeled as a Differential Cooperative Game-Theoretic framework, in which the human and the robot represent two players. 
        The objective of the RNN is to predict at each time instant the human's desired trajectory, within a certain time horizon. This allows to arbitrate between the human and the robot desired trajectories, and allows the robot to be more assistive to the human.
        Due to the amount of data required for the training, and due to the fact that, once the model is instructed and used, also the system is affected and then a fine re-training is required, the training procedure is divided into two main steps.
        A first iterative training is performed by one user. 
        This step requires some more data and training time. Indeed, being it iterative, it requires a limited number (2/3 iterations) of iteration, re-training of the model, more data collection and so on.
        After this procedure (necessary only once), a transfer learning layer is also implemented, to allow a fast re-training of the model on each new user. 
        With this procedure it is possible to quickly adapt the model.
        Experiments with a real robotic platform show the utility of the initial iterative procedure to improve the predicting capabilities, and the feasibility of the quick transfer learning.
      </p>
    </li>     -->
    <!-- <p class="on-clic" data-rel="2">Thesis 2</p>
    <li class="old-thesis">
      <p>esempio di tesi due </p>
    </li> -->
  </ul>   
</div>

<script>

$(document).ready(function(){
$("li.old-thesis").hide();
});

$(function($) {
    $('p.on-clic').click(function() {
    $('li.old-thesis:nth-of-type('+$(this).data('rel')+')').show().siblings(".old-thesis").hide();
});
})(jQuery);

</script>

  
</div>



<div class="footer">
  <div id="social"></div>
</div>





</body>
</html> 
